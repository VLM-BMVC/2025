# Workshop Advocacy: Vision Language Models — Security, Transparency, and Explainability

---

## ![Workshop Banner Placeholder](banner_placeholder.png)
<!-- Replace 'banner_placeholder.png' with your actual banner image file when available -->

---

## Workshop Title
**Vision Language Models: Security, Transparency and Explainability**

---

## Organizing Team

<table>
<tr>
<td width="130"><img src="lakshmi_babu_saheer.png" alt="Dr Lakshmi Babu Saheer" width="120"/><br/><sub><b>Dr Lakshmi Babu Saheer</b></sub></td>
<td width="130"><img src="mahdi_maktabdar_oghaz.png" alt="Dr Mahdi Maktabdar Oghaz" width="120"/><br/><sub><b>Dr Mahdi Maktabdar Oghaz</b></sub></td>
</tr>
</table>

- **Dr Lakshmi Babu Saheer**  
  Director of Computing Informatics and Applications Research group  
  Assistant Professor in AI, Anglia Ruskin University, UK  
  lakshmi.babu-saheer@aru.ac.uk

- **Dr Mahdi Maktabdar Oghaz**  
  Assistant Professor in AI, Anglia Ruskin University, UK  
  mahdi.maktabdar@aru.ac.uk

---

## Keynote Speakers

<table>
<tr>
<td width="130"><img src="keynote_speaker_1.png" alt="Keynote Speaker 1" width="120"/><br/><sub><b>Speaker Name 1</b></sub></td>
<td width="130"><img src="keynote_speaker_2.png" alt="Keynote Speaker 2" width="120"/><br/><sub><b>Speaker Name 2</b></sub></td>
<!-- Add more keynote speakers as needed -->
</tr>
</table>

### Speaker Name 1

_Bio:_  
*Placeholder for keynote speaker 1 bio. Replace with actual biography and credentials.*

---

### Speaker Name 2

_Bio:_  
*Placeholder for keynote speaker 2 bio. Replace with actual biography and credentials.*

---

## Workshop Description

Vision-Language Models (VLMs) have rapidly emerged as a transformative paradigm in AI, combining the power of computer vision and natural language processing to enable systems that can interpret, generate, and reason about visual and textual data jointly. These models underpin a wide range of applications, including image captioning, visual question answering (VQA), content moderation, medical image analysis, robotics, autonomous vehicles, and assistive technologies.

While the capabilities of VLMs continue to grow, significant concerns have surfaced regarding their security, transparency, and explainability—particularly as these models are increasingly deployed in high-stakes and sensitive real-world scenarios. This workshop aims to bring together researchers and practitioners from the computer vision, NLP, machine learning, and security communities to address the core technical challenges and ethical implications of deploying VLMs in practice.

The central focus of this workshop is to explore the following interrelated themes and subthemes:

---

### **Theme 1: Building and Optimizing Vision-Language Models (VLMs)**

**Subthemes:**
- Architecture innovations in unified and modular VLMs (e.g., BLIP, GIT, Flamingo)
- Multimodal pretraining strategies: contrastive, generative, masked modeling
- Data quality and curation for diverse, inclusive, and robust multimodal learning
- Efficient and scalable training: distillation, low-resource adaptation, green AI
- Multilingual and multicultural capabilities for global deployment
- Benchmarking and evaluation metrics for VLM tasks

---

### **Theme 2: Security, Robustness, and Trustworthiness for VLMs**

**Subthemes:**
- Adversarial attacks and prompt manipulation in multimodal contexts
- Data poisoning, backdoors, and model integrity threats
- Robustness under distribution shifts and real-world deployment conditions
- Misinformation, hallucination, and multimodal disinformation
- Defense mechanisms and robust training strategies

---

### **Theme 3: Transparency, Interpretability, and Explainability of VLMs**

**Subthemes:**
- Visualizing cross-modal attention and internal representations
- Post-hoc explanations for VQA, captioning, and retrieval
- Contrastive and counterfactual explanation techniques
- Human-aligned explanations for actionable understanding
- Evaluation of explanations: user trust, fidelity, and usefulness

---

### **Theme 4: Auditing, Fairness, and Responsible Deployment of VLMs**

**Subthemes:**
- Bias and fairness in outputs across gender, culture, and language
- Dataset and model audits for transparency and accountability
- Training data attribution and model debugging tools
- Legal and ethical compliance (e.g., EU AI Act, AI risk classification)
- Societal impact: deepfakes, disinformation, and responsible innovation

---

*Note: Themes are intentionally broad to encourage wide participation. Depending on community interest, future workshops may focus on more specific themes within the VLM domain.*

---

## Keywords

Vision Language models, Security in VLMs, Transparency and Interpretability in VLMs
